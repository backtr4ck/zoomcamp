{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"test\").getOrCreate()\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\").csv(\n",
    "    \"/sparkdata/data/fhv_tripdata_2019-10.csv.gz\", inferSchema=True\n",
    ")\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1897493"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(6).write.parquet(\"/sparkdata/data/parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.withColumn(\"pickup_date\", F.to_date(df.pickup_datetime)).filter(\n",
    "    \"pickup_date = '2019-10-15'\"\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable(\"fhv_2019_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|pickup_date|         duration|\n",
      "+-----------+-----------------+\n",
      "| 2019-10-28|       3.786915E7|\n",
      "| 2019-10-11|       3.786915E7|\n",
      "| 2019-10-31|       5260346.45|\n",
      "| 2019-10-01|4207681.683333334|\n",
      "| 2019-10-17|         527640.0|\n",
      "| 2019-10-26|         527050.0|\n",
      "| 2019-10-30|87872.06666666667|\n",
      "| 2019-10-25|          63409.6|\n",
      "| 2019-10-02|46153.88333333333|\n",
      "| 2019-10-23|          44737.0|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "    to_date(pickup_datetime) AS pickup_date,\n",
    "    MAX((CAST(dropOff_datetime AS LONG) - CAST(pickup_datetime AS LONG)) / 60) AS duration\n",
    "FROM \n",
    "    fhv_2019_10\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631152.5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"3.786915E7\") / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = spark.read.option(\"header\", \"true\").csv(\"/sparkdata/data/taxi_zone_lookup.csv\")\n",
    "zones.registerTempTable(\"zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LocationID', 'Borough', 'Zone', 'service_zone']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                zone|count(1)|\n",
      "+--------------------+--------+\n",
      "|         Jamaica Bay|       1|\n",
      "|Governor's Island...|       2|\n",
      "| Green-Wood Cemetery|       5|\n",
      "|       Broad Channel|       8|\n",
      "|     Highbridge Park|      14|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "    pul.zone,\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    fhv_2019_10 fhv LEFT JOIN zones pul ON fhv.PULocationID = pul.LocationID\n",
    "                      LEFT JOIN zones dol ON fhv.DOLocationID = dol.LocationID\n",
    "GROUP BY \n",
    "    1\n",
    "ORDER BY\n",
    "    2 ASC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
